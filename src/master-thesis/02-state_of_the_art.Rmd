\setcounter{section}{1}

# State of the art

In 1902, Bertrand Russell wrote Gottlob Frege a letter, pointing out a paradox in Gottlob's _Begriffsschrift_ [@Frege]. Up until this point mathematicians expected that everything could be grouped in sets, as initially demonstrated by Georg Cantor in 1874 [@Cantor]. Russell's paradox gave a contradiction to this assumption:

Given the set of all sets that do not contain themselfs $R = \{x|x\not \in x\}$, then $R\in R$ and $R\not\in R$.

To fix this problem, Russell added a basic theory of types in the appendix of _pricipia mathematica_ [@Principia_Mathematica], that at the time was currently in the printer. This rushed theory was not perfect, but it marks the first appearance of type theory.

## Type Theory

The main idea behind type theory is that every element has exactly one type. Once the type of an element is given, it can not change. This is a big difference to sets, where elements can live in any amount of different sets.

Russells original theory had the type of functions not only depend on the types of its arguments but also on any type that is used in the definition of the function. Thus the type of a functions could get very complicated even for simple functions.

In 1921 Leon Chwistek and Frank Ramsey noticed that if one would allow recursive type definitions, the complexity could be avoided. This new theory is general referred as _simple type theory_, tough its still far from simple.

At that time another method of dealing with Russell's paradox was Ernst Zermelo's axiomatic set theory. That then was further refined by Abraham Fraenkel in 1920 to what is know known as Zermelo-Fraenkels set theory (ZF). Mathematicians would then continue using ZF over type theory, as is was more expressive.

It was only in the 1950s that type theory found its use in computer science with Fortran being one of the first programming language with a compiler and an type checker. Similiar, but less known languages with type checkers where invented around the same time.

Between 1934 and 1969 Haskell Curry and William Howard noticed that proofs could be represented as programs with the proven statement being the type of said program. This realization, now known as the _Curry-Howard-Correspondence_, resulted in the invention of proof checking programs.

The next big step for type theory was in 1972 as Per Martin-Löf introduced a new form of type theory, now known as the Martin-Löf type theory. Martin-Löf took the Curry-Howard-Correspondence and exend it to be able to write statements in predicate logic. To do so, he introduced dependent types. Dependent types essentially extended typicall type theory with quanfifiers. Note that dependent types to not use predicate logic but are rather dependent types are equivalent to statements written in predicate logic.

## Dependent types and Refinement types

Because dependent types have the same expressivness as statements in predicate logic it can be used to check proofs written in predicate logic. This checking process in currently still far from automatic, but it has the benifit of producing bulletproof proofs. If instead we want to use types for automatic checking or even proving, then dependent types can't help. Instead we need a type system that includes a method of proving any statement written in it. Such types are called refinement types.

The main theory behind refinement types was developed by Tim Freeman and Frank Pfenning in 1991 in the paper titled _Refinement Types for ML_ [@refinement_types_for_ML]. The original paper only allowed the predicated $\land$ and $\lor$ to reason about types. The underlying method for infering the types was based on the already implemented type inference for ML.